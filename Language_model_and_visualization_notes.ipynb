{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Language model and visualization notes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "x9wPoTMfekOS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvdheram/Stereotypical-Social-bias-detection-/blob/Pre-trained-LM-selection-and-training/Language_model_and_visualization_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WvKa-oSJrxq"
      },
      "source": [
        "# Language models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2i-Sr614PTb"
      },
      "source": [
        "## BERT \n",
        "\n",
        "Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
        "\n",
        "Link : https://arxiv.org/pdf/1810.04805.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bBbM9kk4dNL"
      },
      "source": [
        "Bert - **B**idirecitonal **E**ncoder **R**epresentations from **t**ransformers\n",
        "\n",
        "Architecture :\n",
        "  * Multi-layer, **bidirectional** , encoder - based transformer \n",
        "  * BERT-base - 12 Encoder stacks, 768 hidden size, 12 - Self attention head\n",
        "\n",
        "Framework :\n",
        "\n",
        "  * BERT-tokenizer :\n",
        "    * **WordPiece** embeddings \n",
        "    * Vocab size : 30,000\n",
        "    * First token `[CLS]` - The final hidden state of the 12th encoder stack\n",
        "    * Two sequences seperated by `[SEP]` \n",
        "    * End of sequence indicated by `[EOS]`\n",
        "\n",
        "    * Input : Input sentence\n",
        "    * Output : Token embedding + segment embedding + Position embedding \n",
        "    * \"BERT uniformly selects 15% of the input tokens for possible replacement. Of the selected tokens, 80% are replaced with [MASK], 10% are left unchanged,and 10% are replaced by a randomly selected vocabulary token.\" [RoBERTa paper]\n",
        "  \n",
        "  * Pre-training\n",
        "    * Task1 : Masked language model (MLM)\n",
        "      * For deep bidirectional representation, mask 15 % of all Wordpiece tokens in each sequence at random and predict the masked tokens.\n",
        "    * Task2 : Next sentence prediction (NSP)\n",
        "      * Trained to understand relationships between two sentences (Q&A, NLI)\n",
        "    * Data\n",
        "      * BookCorpus (800M words)\n",
        "      * English wikipedia (2500M words)\n",
        "  * Fine-tuning\n",
        "    * Plug-in task specific output layer and fine-tune all the parameters end to end.\n",
        "    * At output, the first token i.e `[CLS]` representation is fed into output layer for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3L3CzAu4eKL"
      },
      "source": [
        "## GPT-2\n",
        "\n",
        "Links :\n",
        "\n",
        "1. http://www.persagen.com/files/misc/radford2019language.pdf\n",
        "2. https://youtu.be/Ck9-0YkJD_Q?t=936\n",
        "3. https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf \n",
        "\n",
        "Model specification :\n",
        "  * 12- layer decoder- only transformer \n",
        "  * Masked self-attention heads (768 dimentional states and 12 attention heads)\n",
        "\n",
        "Basic Blocks of GPT architecture [2,3] :\n",
        "  1. GPT2 Tokenizer \n",
        "    * **Input** : Sentence \n",
        "    * **Output** : input_ids, attention_mask, labels \n",
        "    * **Vocab size** : 50k \n",
        "    * **Encoding** : Byte pair encoding (BPE) - \"Middle gorund between character level encoding and word level encoding\" [1] \n",
        "  2. GPT-2 embedding block [2] :\n",
        "      * Consists of \n",
        "        * Word embedding layer \n",
        "        * Position embedding layer\n",
        "      * **Input** : (input_ids, attention_mask, labels)- size (1,8) [*sentence, tokens*]\n",
        "      * **Output** : size (1,8,768) - [*sentence, tokens, embeddings per token*]\n",
        "  3. GPT-2 Decoder Block (x12):\n",
        "    * Consists of \n",
        "      * Attention block [2]:\n",
        "        * Consists of \n",
        "          * Self attention mechanism  ( generating Query, key, value pairs etc. of transformer) \n",
        "      * Multi layer perceptron block/ feedforward layer (MLP - Block)\n",
        "          * Consists of \n",
        "            * layer norm, convolution , activaiton function, dropout \n",
        "      * Layer Normalization \n",
        "  4. LM head layer \n",
        "    * Consists of Linear layer projected to vocab  \n",
        "\n",
        "Training data :\n",
        "  * WebText ( Web pages curated and filtered by humans - 45 million)\n",
        "    * Starting point, scraped outbound links from reddit (>3 karma)\n",
        "\n",
        "GPT2 for text classification :\n",
        "  * Remove the LM head and attach a classification layer with the output dimention equal to size of labels. \n",
        "  * Grab the output of last word embedding in the seqence because it has context information (L-R LM) until that word int he input sequence.\n",
        "    * transformer_output[0] (https://huggingface.co/transformers/_modules/transformers/models/gpt2/modeling_gpt2.html#GPT2ForSequenceClassification) \n",
        "    * Sequence classification architecture:\n",
        "      * Pooled output (last output as mentioned above)\n",
        "      * Dropout(0.1)\n",
        "      * Linear classifier layer with size (input_dim, num_class lables)\n",
        "      * Sigmoid Layer + BCE loss function \n",
        "\n",
        "\n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyiRQ5uL6EAL"
      },
      "source": [
        "## XL-Net (TBD)\n",
        "\n",
        "Link : https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LICnoEFo6BwM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtg-Q1jo6HVy"
      },
      "source": [
        "## RoBERTa \n",
        "\n",
        "Link : https://arxiv.org/abs/1907.11692\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JnFSdIBGDbT"
      },
      "source": [
        "Optimized version of BERT with the following modificatoins:\n",
        "  * Removing next sentence prediction (NSP) \n",
        "  * Training on more data and bigger batches\n",
        "  * Training on longer sequences \n",
        "  * Dynamically changing the masking pattern applied to training data.\n",
        "\n",
        "Data:\n",
        "  * Increase data size to imrpove end task performance \n",
        "  * BookCorpus + Wikipedia : Original data used by BERT \n",
        "  * CC- News : English portion of CommonCrawl News dataset ( \"63 million articles crawled between September 2016 and feb 2019 - 76 GB after filtering\")\n",
        "  * OPENWEBTEXT - \"The text is web content extracted from URLs shared on Reddit with at least three upvotes. (38GB)\"\n",
        "  * \"STORIES, a dataset introduced in Trinh and Le\n",
        "(2018) containing a subset of CommonCrawl\n",
        "data filtered to match the story-like style of\n",
        "Winograd schemas. (31GB)\".\n",
        "\n",
        "Training procedure :\n",
        "  * Statis (BERT) vs Dynamic (RoBERTa) masking\n",
        "    * Dynamic masking is a strategy where masking patterns are generated for every sequence being fed into the model rather than relying on randomly masking and predicting.\n",
        "  * Model input format and Next sentence prediction \n",
        "    * Doument-sentences : Inputs to the model are packed with full sentences which do not cross document boundaries. Remove NSP loss \n",
        "  * Training with larger batch sizes \n",
        "    * 8k batch size increased when compared to BERT.\n",
        "  * Text encoding :\n",
        "    * Byte Pair encoding [BPE] which relies on subword units extracted from the training corpus compared to  BERT character level "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9wPoTMfekOS"
      },
      "source": [
        "## Visualization (TBD)\n",
        "\n",
        "Link: https://towardsdatascience.com/visualize-bert-sequence-embeddings-an-unseen-way-1d6a351e4568\n",
        "\n",
        "\n",
        "1. https://jalammar.github.io/explaining-transformers/\n",
        "2. https://jalammar.github.io/hidden-states/\n",
        "3. BerViz : https://github.com/jessevig/bertviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjnkFSkge2TE"
      },
      "source": [
        "Bert-base:\n",
        "  * 12 encoder-layer stack for building contextualized embeddings.\n",
        "  * 100 million tuneable parameters.\n",
        "  * As bert model offers its embeddings to input, its useful to viusalize layers to analyze the patterns learned on unseen data.\n",
        "\n",
        "\n",
        "Why?\n",
        "  * After training viusalize, how well each layer seperates over epochs.\n",
        "\n",
        "How?\n",
        "  * BertForSequenceClassification consists of :\n",
        "    * 1 - BertEmbedding layer -> 12 - Bertlayer -> 1 - Bertpooler -> Tanh - activation -> Dropout layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4AwkYpm6M5b"
      },
      "source": [
        "# Compilation of results \n",
        "\n",
        "Reference : https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDYBrXYROZTA"
      },
      "source": [
        "### Hyper-parameter search "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h2vFkB5OcmY"
      },
      "source": [
        "h_params_compiled = pd.read_csv('/content/h_params_compiled.csv', index_col= 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ytCwyYwOp7Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "0b1053b4-bad7-4259-c329-2ceac7a75553"
      },
      "source": [
        "h_params_compiled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>num_train_epochs</th>\n",
              "      <th>seed</th>\n",
              "      <th>per_device_train_batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>roberta-base</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>5</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xlnet-base-cased</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gpt2</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          model_name  learning_rate  ...  seed  per_device_train_batch_size\n",
              "0       roberta-base       0.000034  ...    22                            8\n",
              "1   xlnet-base-cased       0.000025  ...    15                           32\n",
              "2  bert-base-uncased       0.000025  ...    15                           32\n",
              "3               gpt2       0.000025  ...    15                           32\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQP-ex2iX9wP"
      },
      "source": [
        "### Loading the metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQfIxc4HYEio"
      },
      "source": [
        "bert = open('/content/eval_results_BERT_0.5_.json','r')\n",
        "roberta = open('/content/eval_results_RoBERTa_0.5_.json','r')\n",
        "gpt2 = open('/content/eval_results_gpt-2_0.5_.json','r')\n",
        "xlnet = open('/content/eval_results_xlnet_0.5_.json','r')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhUcTXUWaJpS"
      },
      "source": [
        "import json \n",
        "import pandas as pd\n",
        "\n",
        "bert_metrics = json.load(bert)\n",
        "roberta_metrics = json.load(roberta)\n",
        "gpt2_metrics = json.load(gpt2)\n",
        "xlnet_metrics = json.load(xlnet)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiCFqDjbqaMQ"
      },
      "source": [
        "### Sample_average precision, recall, f1-score (TBD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPGGBl8Osyfw"
      },
      "source": [
        "#### Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSPLOrE8quuc"
      },
      "source": [
        "'Sample_average':\n",
        "\n",
        "* Calculate metrics for each instance, and find their average (only meaningful for multilabel classification where this differs from accuracy_score)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrXZ0Yes12h"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGwPXKFrHEr9"
      },
      "source": [
        "bert_metrics['sample_average_f1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtuIqCgnqqgY"
      },
      "source": [
        "metrics = ['sample_average_precision','sample_average_recall','sample_average_f1']\n",
        "results = [bert_metrics,roberta_metrics,gpt2_metrics,xlnet_metrics]\n",
        "model_name = ['bert','roberta','gpt2','xlnet']\n",
        "\n",
        "sample_avg_scores = {}\n",
        "\n",
        "for index,result in enumerate(results):\n",
        "  for metric in metrics:\n",
        "    sample_avg_scores[model_name[index]+ \"_\"+ metric] = result[metric]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIaW3PK5MDH_"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame.from_records(sample_avg_scores, index = [0]).T\n",
        "df.reset_index(drop = False, inplace = True )\n",
        "df.columns = ['Model_name','sample_average_score']"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqy7LP6yO_BX"
      },
      "source": [
        "df_bert  = df.iloc[0:3]\n",
        "df_bert_metrics = df_bert.copy()\n",
        "df_bert_metrics['Model_name'] = 'bert_base_uncased'\n",
        "df_bert_metrics.index = ['precision','recall','fmeasure']\n",
        "df_bert_metrics = df_bert_metrics.set_index(['Model_name',df_bert_metrics.index])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV-dqUQYTMO1"
      },
      "source": [
        "df_roberta = df.iloc[6:9]\n",
        "df_roberta_metrics = df_roberta.copy()\n",
        "df_roberta_metrics['Model_name'] = 'roberta-base'\n",
        "df_roberta_metrics.index = ['precision','recall','fmeasure']\n",
        "df_roberta_metrics = df_roberta_metrics.set_index(['Model_name',df_roberta_metrics.index])"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AaxnGmgTMPV"
      },
      "source": [
        "df_GPT2 = df.iloc[3:6]\n",
        "df_GPT2_metrics = df_GPT2.copy()\n",
        "df_GPT2_metrics['Model_name'] = 'gpt2'\n",
        "df_GPT2_metrics.index = ['precision','recall','fmeasure']\n",
        "df_GPT2_metrics = df_GPT2_metrics.set_index(['Model_name',df_GPT2_metrics.index])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVZ44sgZTMPV"
      },
      "source": [
        "df_XLNet = df.iloc[9:]\n",
        "df_XLNet_metrics = df_XLNet.copy()\n",
        "df_XLNet_metrics['Model_name'] = 'xlnet-base-cased'\n",
        "df_XLNet_metrics.index = ['precision','recall','fmeasure']\n",
        "df_XLNet_metrics = df_XLNet_metrics.set_index(['Model_name',df_XLNet_metrics.index])"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkV_vWs3TMPW"
      },
      "source": [
        "df_per_label = pd.concat([df_bert_metrics,df_roberta_metrics,df_XLNet_metrics,df_GPT2_metrics])"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "NNs4btuXTMPW",
        "outputId": "2241a868-c7e8-46cc-b201-487c411c78ee"
      },
      "source": [
        "df_per_label"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sample_average_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">bert_base_uncased</th>\n",
              "      <th>precision</th>\n",
              "      <td>0.819245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.843137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fmeasure</th>\n",
              "      <td>0.813054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">roberta-base</th>\n",
              "      <th>precision</th>\n",
              "      <td>0.876430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.880338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fmeasure</th>\n",
              "      <td>0.875302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">xlnet-base-cased</th>\n",
              "      <th>precision</th>\n",
              "      <td>0.784985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.869057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fmeasure</th>\n",
              "      <td>0.742949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">gpt2</th>\n",
              "      <th>precision</th>\n",
              "      <td>0.582487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.691714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fmeasure</th>\n",
              "      <td>0.530620</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             sample_average_score\n",
              "Model_name                                       \n",
              "bert_base_uncased precision              0.819245\n",
              "                  recall                 0.843137\n",
              "                  fmeasure               0.813054\n",
              "roberta-base      precision              0.876430\n",
              "                  recall                 0.880338\n",
              "                  fmeasure               0.875302\n",
              "xlnet-base-cased  precision              0.784985\n",
              "                  recall                 0.869057\n",
              "                  fmeasure               0.742949\n",
              "gpt2              precision              0.582487\n",
              "                  recall                 0.691714\n",
              "                  fmeasure               0.530620"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXrIJvr9s3qO"
      },
      "source": [
        "#### Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us2uOQsCUwuB"
      },
      "source": [
        "* Sample average scores of Roberta are slightly better when compared to bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdPzxCq942f-"
      },
      "source": [
        "### Micro_avg_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibw20dvBK_4Q"
      },
      "source": [
        "#### Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XLJ_xlSLEOR"
      },
      "source": [
        "Quality of overall classification is defined by \n",
        "  * Micro-average :  \n",
        "    * Favours bigger classes; not preferable if the data is skewed. ??\n",
        "    * Average per-text decision. (Based on total number of text examples)\n",
        "    * Micro-averaged scores are calculated per sample instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2RFBlRoLVCP"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5rHpvIaczXV"
      },
      "source": [
        "micro_avg_lms = pd.DataFrame([bert_metrics['Classification_report']['micro avg'],roberta_metrics['Classification_report']['micro avg'],gpt2_metrics['Classification_report']['micro avg'],xlnet_metrics['Classification_report']['micro avg']],index=['bert-base-uncased','roberta-base','gpt2','xlnet-base-cased'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHb9yRfJlyjv"
      },
      "source": [
        "micro_avg_lms.columns = pd.MultiIndex.from_product([micro_avg_lms.columns, ['micro avg']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_bKtSHhnuYT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c58c658c-5a95-4627-d794-4172def0ee0e"
      },
      "source": [
        "micro_avg_lms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>micro avg</th>\n",
              "      <th>micro avg</th>\n",
              "      <th>micro avg</th>\n",
              "      <th>micro avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bert-base-uncased</th>\n",
              "      <td>0.824537</td>\n",
              "      <td>0.822633</td>\n",
              "      <td>0.823584</td>\n",
              "      <td>4330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>roberta-base</th>\n",
              "      <td>0.864859</td>\n",
              "      <td>0.869053</td>\n",
              "      <td>0.866951</td>\n",
              "      <td>4330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpt2</th>\n",
              "      <td>0.849421</td>\n",
              "      <td>0.457275</td>\n",
              "      <td>0.594505</td>\n",
              "      <td>4330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xlnet-base-cased</th>\n",
              "      <td>0.880033</td>\n",
              "      <td>0.736952</td>\n",
              "      <td>0.802162</td>\n",
              "      <td>4330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  precision    recall  f1-score   support\n",
              "                  micro avg micro avg micro avg micro avg\n",
              "bert-base-uncased  0.824537  0.822633  0.823584      4330\n",
              "roberta-base       0.864859  0.869053  0.866951      4330\n",
              "gpt2               0.849421  0.457275  0.594505      4330\n",
              "xlnet-base-cased   0.880033  0.736952  0.802162      4330"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYqyI4cpKsTD"
      },
      "source": [
        "#### Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI2kBtxMKwQ6"
      },
      "source": [
        "* **roberta-base** has higher f1-score, recall, **XLNet** precision higher when compared to others"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEmRv45d48lH"
      },
      "source": [
        "### Macro_avg_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vltfQ7fGLFnx"
      },
      "source": [
        "#### Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iopE_oz_LHVY"
      },
      "source": [
        "Quality of overall classification is defined by \n",
        "  * Macro-average :\n",
        "    * A measure is the average of the same measures calculated for C classes.\n",
        "    * Macro-averaging treats all classes equally.\n",
        "    * Average per-class measure (considers the classifier predictions rather than the datasets counts??)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqhbAqpgLXIU"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I7zBk303KI3"
      },
      "source": [
        "macro_avg_lms = pd.DataFrame([bert_metrics['Classification_report']['macro avg'],roberta_metrics['Classification_report']['macro avg'],gpt2_metrics['Classification_report']['macro avg'],xlnet_metrics['Classification_report']['macro avg']],index=['bert-base-uncased','roberta-base','gpt2','xlnet-base-cased'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aciRTa7a3SZH"
      },
      "source": [
        "macro_avg_lms.columns = pd.MultiIndex.from_product([macro_avg_lms.columns, ['macro avg']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_c3sIuP3b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "df967292-1943-477c-8fac-ba101e7842c8"
      },
      "source": [
        "macro_avg_lms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>macro avg</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>macro avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bert-base-uncased</th>\n",
              "      <td>0.854382</td>\n",
              "      <td>0.842521</td>\n",
              "      <td>0.847510</td>\n",
              "      <td>4330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>roberta-base</th>\n",
              "      <td>0.880783</td>\n",
              "      <td>0.884021</td>\n",
              "      <td>0.882198</td>\n",
              "      <td>4330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpt2</th>\n",
              "      <td>0.792463</td>\n",
              "      <td>0.496030</td>\n",
              "      <td>0.563569</td>\n",
              "      <td>4330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xlnet-base-cased</th>\n",
              "      <td>0.885105</td>\n",
              "      <td>0.772770</td>\n",
              "      <td>0.815378</td>\n",
              "      <td>4330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  precision    recall  f1-score   support\n",
              "                  macro avg macro avg macro avg macro avg\n",
              "bert-base-uncased  0.854382  0.842521  0.847510      4330\n",
              "roberta-base       0.880783  0.884021  0.882198      4330\n",
              "gpt2               0.792463  0.496030  0.563569      4330\n",
              "xlnet-base-cased   0.885105  0.772770  0.815378      4330"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEg1XwTLK1j4"
      },
      "source": [
        "#### Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmmkx0E2K3jR"
      },
      "source": [
        "* XLNet has lower recall but precision is better than other LMS\n",
        "* Overall roberta-base has better score when considering f1-score\n",
        "* bert comes second with a good balance of precision and recall \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj7xFNtXApdx"
      },
      "source": [
        "### Hamming_loss, subset_accuracy\n",
        "\n",
        "References : \n",
        "\n",
        "  1. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html\n",
        "  2. https://mmuratarat.github.io/2020-01-25/multilabel_classification_metrics\n",
        "  3. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
        "  4. https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1ELw_cLITH"
      },
      "source": [
        "#### Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqvy8QwdLK_K"
      },
      "source": [
        "* Hamming loss : \n",
        "  * Fraction of labels incorrectly predicted\n",
        "* Exact match ratio (Aka Accuracy):\n",
        "    * **The average per-text exact classification**\n",
        "    * It is harsh measure as exact match(prediction and true values) are taken into consideration. \n",
        "      * Why?\n",
        "        * In multi-label/class classification, a subset of correct prediction are avoided. \n",
        "    * Its based on some threshold as output probabilities are rounded to 0 if less than threshold and 1 if greater than threshold.\n",
        "* Hamming_score / Accuracy :\n",
        "  * \"Accuracy for each instance is defined as the proportion of the predicted correct labels to the total number (predicted and actual) of labels for that instance. Overall accuracy is the average across all instances. It is less ambiguously referred to as the Hamming score.\" [2]\n",
        "* AUC_ROC curve and score:\n",
        "  * Why?\n",
        "    * Compare ROC (analyze probabilities) AUC score (model performance) of two or three models for binary classification or classes when multi-class.\n",
        "    * AUC - ROC curve is a performance measurement for the classification problems at various threshold settings. \n",
        "    * ROC is a probability curve \n",
        "      * TP vs FP plotted at different thresholds\n",
        "    * AUC represents the degree or measure of separability.\n",
        "      * AUC value ranges from 0 to 1 (perfect)\n",
        "      * AUC is scale invarient \n",
        "      * AUC is classification-threshold-invariant.\n",
        "      * For multi-label/class, extend using one vs All (class 0 vs rest..), one ROC curve per label considering it as one vs rest.\n",
        "  * Sensitivity / True positive rate:\n",
        "    * Proportion of correctly classified positive samples (TP) out of total number (TP+FN) of positive classes.\n",
        "    * **Higher the better**\n",
        "  * Specificity / True Negative rate:\n",
        "    * Proportion of correctly classified negative sample (TN) out of total number of negative classes (TN+FP)\n",
        "    * **Higher the better**\n",
        "  * False Negative rate:\n",
        "    * Proportion of incorrectly classified positive class (FN) out of total number correctly predicted classes (TP + TN) by classifier.\n",
        "    * **Lower the better**\n",
        "  * False positive rate (1- Specificity) :\n",
        "    * Proportion of incorrectly classified negaitve class out of total number of correctly predicted negative class and incorrectly predicted positive class (TN + FP)\n",
        "    * **Lower the better**.\n",
        "  \n",
        "  * Probability of predicitons\n",
        "    * `Predict_proba` gives probability distribution of the prediction across different classes. \n",
        "    * The prediction is thus converted into class label by using decision threshold or threshold.\n",
        "    * Different threshold gives different results, confusion matrices which effect sensitivity and specificity.\n",
        "    * Default value of threshold is 0.5 for prediction scores ranging from 0 to 1.\n",
        "      * Prediction < 0.5 - class 0\n",
        "      * Prediction >= 0.5 - class 1\n",
        "    * Default might not always work.\n",
        "    * AUC-ROC curve gives a cumulative view of results for different threshold, thus provide a visualization to choose best threshold.\n",
        "  * Receiver Operator Characteristic (ROC) curve :\n",
        "    * Curve that plots TPR (sensitivity) and FPR (1-Specificity) probability for different thresholds.\n",
        "      * X-axis - False positive rate\n",
        "      * Y-axis - True positive rate\n",
        "      * Ideal : \n",
        "        * Higher value on y-axis and lower value on x-axis.\n",
        "          * Higher true positive rate than False positive rate.\n",
        "            \n",
        "    * Area under the curve (AUC) is the area under the ROC.\n",
        "      * \"The higher the AUC, the better the performance of the model at distinguishing between the positive and negative classes.\"\n",
        "      1. AUC = 1 - Perfect classifier\n",
        "      2. `0.5<AUC<1` - Better classifier\n",
        "      3. AUC = 0.5 - Random guess\n",
        "      4. AUC = 0 - Worst classifier (Neg as pos and pos as neg)\n",
        "      * `sklearn.metrics import roc_auc_score` \n",
        "      * `roc_auc_score(true,pred)`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToUlQujLOVs"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-utZSCDs_pZe"
      },
      "source": [
        "bert = bert_metrics['hamming_loss'],bert_metrics['subset_accuracy'],bert_metrics['hamming_score'],bert_metrics['AUC_ROC_score']\n",
        "roberta = roberta_metrics['hamming_loss'],roberta_metrics['subset_accuracy'],roberta_metrics['hamming_score'],roberta_metrics['AUC_ROC_score']\n",
        "gpt2 = gpt2_metrics['hamming_loss'],gpt2_metrics['subset_accuracy'],gpt2_metrics['hamming_score'],gpt2_metrics['AUC_ROC_score']\n",
        "xlnet = xlnet_metrics['hamming_loss'],xlnet_metrics['subset_accuracy'],xlnet_metrics['hamming_score'],xlnet_metrics['AUC_ROC_score']"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H_fewWDJZ8U"
      },
      "source": [
        "hs_metrics = pd.DataFrame([bert,roberta,gpt2,xlnet],index=['bert-base-uncased','roberta-base','gpt2','xlnet-base-cased'],columns=['hamming_loss','subset_accuracy','hamming_score/Accuracy','AUC_ROC_score'])"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjK5Ya5bJrxE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "fda51641-82c0-4f18-9e11-6aec9c3e81b8"
      },
      "source": [
        "hs_metrics"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hamming_loss</th>\n",
              "      <th>subset_accuracy</th>\n",
              "      <th>hamming_score/Accuracy</th>\n",
              "      <th>AUC_ROC_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bert-base-uncased</th>\n",
              "      <td>0.090480</td>\n",
              "      <td>0.649879</td>\n",
              "      <td>0.772663</td>\n",
              "      <td>0.950945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>roberta-base</th>\n",
              "      <td>0.064694</td>\n",
              "      <td>0.789283</td>\n",
              "      <td>0.848811</td>\n",
              "      <td>0.968983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpt2</th>\n",
              "      <td>0.152124</td>\n",
              "      <td>0.331990</td>\n",
              "      <td>0.518466</td>\n",
              "      <td>0.892467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xlnet-base-cased</th>\n",
              "      <td>0.091516</td>\n",
              "      <td>0.576954</td>\n",
              "      <td>0.729654</td>\n",
              "      <td>0.956161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   hamming_loss  ...  AUC_ROC_score\n",
              "bert-base-uncased      0.090480  ...       0.950945\n",
              "roberta-base           0.064694  ...       0.968983\n",
              "gpt2                   0.152124  ...       0.892467\n",
              "xlnet-base-cased       0.091516  ...       0.956161\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPckm459K4fx"
      },
      "source": [
        "#### Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_17OJHHnK6Gw"
      },
      "source": [
        "* Hamming loss (main_metric for multi-label) is lowest for roberta-base .\n",
        "* AUC_ROC score of roberta-base has a slight margin over Xlnet and bert "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuIJD9PYLCzO"
      },
      "source": [
        "### per_class_precision_recall_fmeasure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq2eDdDpLbbK"
      },
      "source": [
        "#### Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn93wxubLd1A"
      },
      "source": [
        "References : http://rali.iro.umontreal.ca/rali/sites/default/files/publis/SokolovaLapalme-JIPM09.pdf \n",
        "\n",
        "Precision : \n",
        "  * The number of correctly classified positive examples divided by the number of examples labeled by the model as positive.\n",
        "  * Percentage of \"correctly **predicted** (positive)\" class labels by model out of total correct predictions (positive).\n",
        "  * Agreement of the data class labels with those of a classifiers if calculated from sums of per-text decisions. \n",
        "\n",
        "\n",
        "Recall : \n",
        "  * The number of correctly classified positive examples divided by the number of positive examples in the data.\n",
        "  * Percentage of **identified positive sample** out of total positive labels in the data.\n",
        "  * Effectiveness of a classifier to identify class labels if calculated from sums of per-text decisions.\n",
        "\n",
        "F1-Measure:\n",
        "  * Harmonic mean of Precision and recall \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV9Ic0JmLeMD"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19FUoVteTqV4"
      },
      "source": [
        "model = {}\n",
        "Labels = ['Ethnicity','gender','profession','religion','Anti-stereotype','stereotype','unrelated']\n",
        "# model = ['bert_base_uncased','roberta-base','gpt2','xlnet-base-cased']\n",
        "metrics = [bert_metrics,roberta_metrics,gpt2_metrics,xlnet_metrics]\n",
        "model_name = ['bert','roberta','gpt2','xlnet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjgisvfCLPa2"
      },
      "source": [
        "model.clear()\n",
        "for index,metric in enumerate(metrics):\n",
        "  for label in Labels:\n",
        "    model[model_name[index] + \"_\"+ label] = metric['Classification_report'][label]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9_mPyTJ4w3c"
      },
      "source": [
        "df = pd.DataFrame(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "xb4m2qCCEDLZ",
        "outputId": "a66e8ac7-32fd-429e-e7bd-4977c5058cc6"
      },
      "source": [
        "df.iloc[:,14:21]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gpt2_Ethnicity</th>\n",
              "      <th>gpt2_gender</th>\n",
              "      <th>gpt2_profession</th>\n",
              "      <th>gpt2_religion</th>\n",
              "      <th>gpt2_Anti-stereotype</th>\n",
              "      <th>gpt2_stereotype</th>\n",
              "      <th>gpt2_unrelated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.874640</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>0.732468</td>\n",
              "      <td>0.924915</td>\n",
              "      <td>0.404762</td>\n",
              "      <td>0.890110</td>\n",
              "      <td>0.867886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.774235</td>\n",
              "      <td>0.171053</td>\n",
              "      <td>0.603854</td>\n",
              "      <td>0.924915</td>\n",
              "      <td>0.021851</td>\n",
              "      <td>0.302804</td>\n",
              "      <td>0.673502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.821380</td>\n",
              "      <td>0.284932</td>\n",
              "      <td>0.661972</td>\n",
              "      <td>0.924915</td>\n",
              "      <td>0.041463</td>\n",
              "      <td>0.451883</td>\n",
              "      <td>0.758437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>784.000000</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>467.000000</td>\n",
              "      <td>293.000000</td>\n",
              "      <td>778.000000</td>\n",
              "      <td>1070.000000</td>\n",
              "      <td>634.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           gpt2_Ethnicity  gpt2_gender  ...  gpt2_stereotype  gpt2_unrelated\n",
              "precision        0.874640     0.852459  ...         0.890110        0.867886\n",
              "recall           0.774235     0.171053  ...         0.302804        0.673502\n",
              "f1-score         0.821380     0.284932  ...         0.451883        0.758437\n",
              "support        784.000000   304.000000  ...      1070.000000      634.000000\n",
              "\n",
              "[4 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0OXBkzb5IgP"
      },
      "source": [
        "df_bert  = df.iloc[:,:7]\n",
        "df_bert_metrics = df_bert.copy()\n",
        "df_bert_metrics['Model_name'] = 'bert_base_uncased'\n",
        "df_bert_metrics =df_bert_metrics.set_index(['Model_name',df_bert.index])\n",
        "df_bert_metrics.columns = Labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOhV8z3j9Tot"
      },
      "source": [
        "df_roberta = df.iloc[:,7:14]\n",
        "df_roberta_metrics = df_roberta.copy()\n",
        "df_roberta_metrics['Model_name'] = 'roberta-base'\n",
        "df_roberta_metrics = df_roberta_metrics.set_index(['Model_name',df_bert.index])\n",
        "df_roberta_metrics.columns = Labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "847pgQ97E4UA"
      },
      "source": [
        "df_GPT2 = df.iloc[:,14:21]\n",
        "df_GPT2_metrics = df_GPT2.copy()\n",
        "df_GPT2_metrics['Model_name'] = 'gpt2'\n",
        "df_GPT2_metrics = df_GPT2_metrics.set_index(['Model_name',df_bert.index])\n",
        "df_GPT2_metrics.columns = Labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPGDUAtECJQg"
      },
      "source": [
        "df_XLNet = df.iloc[:,21:]\n",
        "df_XLNet_metrics = df_XLNet.copy()\n",
        "df_XLNet_metrics['Model_name'] = 'xlnet-base-cased'\n",
        "df_XLNet_metrics = df_XLNet_metrics.set_index(['Model_name',df_bert.index])\n",
        "df_XLNet_metrics.columns = Labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K75tImcOFJ43"
      },
      "source": [
        "df_per_label = pd.concat([df_bert_metrics,df_roberta_metrics,df_XLNet_metrics,df_GPT2_metrics])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "cQjalw7pGEGI",
        "outputId": "f84e91b9-5195-408f-984a-666b1242f169"
      },
      "source": [
        "df_per_label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Ethnicity</th>\n",
              "      <th>gender</th>\n",
              "      <th>profession</th>\n",
              "      <th>religion</th>\n",
              "      <th>Anti-stereotype</th>\n",
              "      <th>stereotype</th>\n",
              "      <th>unrelated</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">bert_base_uncased</th>\n",
              "      <th>precision</th>\n",
              "      <td>0.927250</td>\n",
              "      <td>0.870504</td>\n",
              "      <td>0.864583</td>\n",
              "      <td>0.976190</td>\n",
              "      <td>0.613208</td>\n",
              "      <td>0.745079</td>\n",
              "      <td>0.957555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.959184</td>\n",
              "      <td>0.796053</td>\n",
              "      <td>0.888651</td>\n",
              "      <td>0.979522</td>\n",
              "      <td>0.668380</td>\n",
              "      <td>0.707477</td>\n",
              "      <td>0.889590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.942947</td>\n",
              "      <td>0.831615</td>\n",
              "      <td>0.876452</td>\n",
              "      <td>0.977853</td>\n",
              "      <td>0.639606</td>\n",
              "      <td>0.725791</td>\n",
              "      <td>0.922322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>784.000000</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>467.000000</td>\n",
              "      <td>293.000000</td>\n",
              "      <td>778.000000</td>\n",
              "      <td>1070.000000</td>\n",
              "      <td>634.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">roberta-base</th>\n",
              "      <th>precision</th>\n",
              "      <td>0.944030</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.896186</td>\n",
              "      <td>0.983051</td>\n",
              "      <td>0.726753</td>\n",
              "      <td>0.773276</td>\n",
              "      <td>0.965000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.968112</td>\n",
              "      <td>0.888158</td>\n",
              "      <td>0.905782</td>\n",
              "      <td>0.989761</td>\n",
              "      <td>0.652956</td>\n",
              "      <td>0.838318</td>\n",
              "      <td>0.913249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.955919</td>\n",
              "      <td>0.859873</td>\n",
              "      <td>0.900958</td>\n",
              "      <td>0.986395</td>\n",
              "      <td>0.687881</td>\n",
              "      <td>0.804484</td>\n",
              "      <td>0.938412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>784.000000</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>467.000000</td>\n",
              "      <td>293.000000</td>\n",
              "      <td>778.000000</td>\n",
              "      <td>1070.000000</td>\n",
              "      <td>634.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">xlnet-base-cased</th>\n",
              "      <th>precision</th>\n",
              "      <td>0.910843</td>\n",
              "      <td>0.850909</td>\n",
              "      <td>0.870536</td>\n",
              "      <td>0.986207</td>\n",
              "      <td>0.789916</td>\n",
              "      <td>0.804054</td>\n",
              "      <td>0.983271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.964286</td>\n",
              "      <td>0.769737</td>\n",
              "      <td>0.835118</td>\n",
              "      <td>0.976109</td>\n",
              "      <td>0.362468</td>\n",
              "      <td>0.667290</td>\n",
              "      <td>0.834385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.936803</td>\n",
              "      <td>0.808290</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>0.981132</td>\n",
              "      <td>0.496916</td>\n",
              "      <td>0.729316</td>\n",
              "      <td>0.902730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>784.000000</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>467.000000</td>\n",
              "      <td>293.000000</td>\n",
              "      <td>778.000000</td>\n",
              "      <td>1070.000000</td>\n",
              "      <td>634.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">gpt2</th>\n",
              "      <th>precision</th>\n",
              "      <td>0.874640</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>0.732468</td>\n",
              "      <td>0.924915</td>\n",
              "      <td>0.404762</td>\n",
              "      <td>0.890110</td>\n",
              "      <td>0.867886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.774235</td>\n",
              "      <td>0.171053</td>\n",
              "      <td>0.603854</td>\n",
              "      <td>0.924915</td>\n",
              "      <td>0.021851</td>\n",
              "      <td>0.302804</td>\n",
              "      <td>0.673502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.821380</td>\n",
              "      <td>0.284932</td>\n",
              "      <td>0.661972</td>\n",
              "      <td>0.924915</td>\n",
              "      <td>0.041463</td>\n",
              "      <td>0.451883</td>\n",
              "      <td>0.758437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>784.000000</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>467.000000</td>\n",
              "      <td>293.000000</td>\n",
              "      <td>778.000000</td>\n",
              "      <td>1070.000000</td>\n",
              "      <td>634.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Ethnicity      gender  ...   stereotype   unrelated\n",
              "Model_name                                           ...                         \n",
              "bert_base_uncased precision    0.927250    0.870504  ...     0.745079    0.957555\n",
              "                  recall       0.959184    0.796053  ...     0.707477    0.889590\n",
              "                  f1-score     0.942947    0.831615  ...     0.725791    0.922322\n",
              "                  support    784.000000  304.000000  ...  1070.000000  634.000000\n",
              "roberta-base      precision    0.944030    0.833333  ...     0.773276    0.965000\n",
              "                  recall       0.968112    0.888158  ...     0.838318    0.913249\n",
              "                  f1-score     0.955919    0.859873  ...     0.804484    0.938412\n",
              "                  support    784.000000  304.000000  ...  1070.000000  634.000000\n",
              "xlnet-base-cased  precision    0.910843    0.850909  ...     0.804054    0.983271\n",
              "                  recall       0.964286    0.769737  ...     0.667290    0.834385\n",
              "                  f1-score     0.936803    0.808290  ...     0.729316    0.902730\n",
              "                  support    784.000000  304.000000  ...  1070.000000  634.000000\n",
              "gpt2              precision    0.874640    0.852459  ...     0.890110    0.867886\n",
              "                  recall       0.774235    0.171053  ...     0.302804    0.673502\n",
              "                  f1-score     0.821380    0.284932  ...     0.451883    0.758437\n",
              "                  support    784.000000  304.000000  ...  1070.000000  634.000000\n",
              "\n",
              "[16 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 302
        }
      ]
    }
  ]
}