{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine learning classifiers (Baselines).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvdheram/Stereotypical-Social-bias-detection-/blob/Machine-learning-classifiers/Machine_learning_classifiers_(Baselines).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBL5XpyLcEs5"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx-IKYWSTAL-",
        "outputId": "bc84bea6-d47f-4449-e6ab-4a985b311ac4"
      },
      "source": [
        "!pip install ktrain --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 25.3 MB 99 kB/s \n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 43.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 981 kB 45.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 263 kB 57.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 26.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 46.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 468 kB 53.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 32.3 MB/s \n",
            "\u001b[?25h  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs8QWWVHS0kZ"
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8adqvI5gTMnE"
      },
      "source": [
        "df = pd.read_csv('/content/ohe_multilabel.csv', index_col = 0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "iOgFp_bmtsb4",
        "outputId": "75253e16-75b8-484c-a27b-3498b7ff9f44"
      },
      "source": [
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ethnicity</th>\n",
              "      <th>gender</th>\n",
              "      <th>profession</th>\n",
              "      <th>religion</th>\n",
              "      <th>Anti-stereotype</th>\n",
              "      <th>stereotype</th>\n",
              "      <th>unrelated</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Many people live in Ethiopia. The people are v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>My professor is a hispanic man He came here il...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The schoolgirl is walking down the street. She...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>We'll likely fly over Cape Verde on our flight...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I know many people who are Russian. They love ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16539</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Arab people are associated with hi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16540</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Car was a new chemist in our lab.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16541</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The gentlemen stood around the fire, carefully...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16542</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The common ukrainian is a supporter of a floun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16543</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I am a loop nurse.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16544 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Ethnicity  ...                                           sentence\n",
              "0            1.0  ...  Many people live in Ethiopia. The people are v...\n",
              "1            1.0  ...  My professor is a hispanic man He came here il...\n",
              "2            0.0  ...  The schoolgirl is walking down the street. She...\n",
              "3            1.0  ...  We'll likely fly over Cape Verde on our flight...\n",
              "4            1.0  ...  I know many people who are Russian. They love ...\n",
              "...          ...  ...                                                ...\n",
              "16539        0.0  ...                Arab people are associated with hi.\n",
              "16540        0.0  ...                  Car was a new chemist in our lab.\n",
              "16541        0.0  ...  The gentlemen stood around the fire, carefully...\n",
              "16542        0.0  ...  The common ukrainian is a supporter of a floun...\n",
              "16543        0.0  ...                                 I am a loop nurse.\n",
              "\n",
              "[16544 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWJjN78DTbTt"
      },
      "source": [
        "y = df.iloc[:,:-1].values\n",
        "X = df.iloc[:,-1].values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmwCxh0PTc2U",
        "outputId": "7161270b-f6e3-4665-e279-ab222a288f4e"
      },
      "source": [
        "X"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Many people live in Ethiopia. The people are very thin and good at distance running.',\n",
              "       'My professor is a hispanic man He came here illegally',\n",
              "       'The schoolgirl is walking down the street. She is a target for child predators.',\n",
              "       ...,\n",
              "       'The gentlemen stood around the fire, carefully passing the boxing around.',\n",
              "       'The common ukrainian is a supporter of a flounder run government.',\n",
              "       'I am a loop nurse.'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5hdjxMITeVh",
        "outputId": "3bbdf98c-f48a-4b64-87d4-1b0a8b8c956e"
      },
      "source": [
        "y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 1., 0.],\n",
              "       [1., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 1., 0., ..., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvxwBVsaUgMF"
      },
      "source": [
        "MAX_LEN = 50\n",
        "RANDOM_SEED = 47"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAFD-634ULmH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df_text, test_df_text, train_df_labels,test_df_labels = train_test_split(X,y, test_size=0.3, random_state=RANDOM_SEED, stratify = y)\n",
        "val_df_text, test_df_text, val_df_labels,test_df_labels = train_test_split(test_df_text,test_df_labels, test_size=0.5, random_state=RANDOM_SEED,stratify = test_df_labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eJo2msAojg8"
      },
      "source": [
        "LABELS = ['Ethnicity','gender','profession','religion','Anti-stereotype','stereotype','unrelated']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuVhP6A9ZI1y"
      },
      "source": [
        "# Classification metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR-BDeQ-Wrdu"
      },
      "source": [
        "def Accuracy(y_true, y_pred):\n",
        "  temp = 0\n",
        "  for i in range(y_true.shape[0]):\n",
        "      temp += sum(np.logical_and(y_true[i], y_pred[i])) / sum(np.logical_or(y_true[i], y_pred[i]))\n",
        "  return temp / y_true.shape[0]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHt7W1ljoZu6"
      },
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report,hamming_loss, roc_auc_score, accuracy_score,multilabel_confusion_matrix, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "upper, lower = 1, 0\n",
        "LABELS = ['Ethnicity','gender','profession','religion','Anti-stereotype','stereotype','unrelated']\n",
        "\n",
        "def classification_metrics(test_pred,labels,model_name,threshold,label_names = LABELS):\n",
        "\n",
        "  print(\"Evaluation metrics for test set:\")\n",
        "  y_pred = np.where(test_pred > threshold, upper, lower)\n",
        "\n",
        "  ROC_AUC_score = roc_auc_score(test_df_labels, test_pred)\n",
        "  accuracy = accuracy_score(labels, y_pred)\n",
        "  hloss = hamming_loss(labels, y_pred)\n",
        "  hscore = Accuracy(labels, y_pred)\n",
        "\n",
        "  precision_sample_average = precision_score(y_true=labels, y_pred=y_pred, average='samples')\n",
        "  recall_sample_average = recall_score(y_true=labels, y_pred=y_pred, average='samples')\n",
        "  f1_sample_average= f1_score(y_true=labels, y_pred=y_pred, average='samples')\n",
        "\n",
        "  cr = classification_report(labels, y_pred, labels=list(range(len(label_names))), target_names=label_names, output_dict=True)\n",
        "  cf = multilabel_confusion_matrix(test_df_labels, \n",
        "  y_pred)\n",
        "\n",
        "  model_metrics = {}\n",
        "  model_metrics[\"AUC_ROC_score\"] = ROC_AUC_score\n",
        "  model_metrics[\"subset_accuracy\"] = accuracy\n",
        "  model_metrics[\"hamming_loss\"]= hloss\n",
        "  model_metrics[\"hamming_score\"] = hscore\n",
        "\n",
        "  model_metrics['sample_average_precision'] = precision_sample_average\n",
        "  model_metrics['sample_average_recall'] = recall_sample_average\n",
        "  model_metrics['sample_average_f1'] = f1_sample_average\n",
        "\n",
        "\n",
        "  if write_to_file:\n",
        "    model_metrics[\"Classification_report\"] = cr\n",
        "\n",
        "    for i,val in enumerate(LABEL_COLUMNS):\n",
        "      model_metrics['confusion_matrix' + '_' + val] = str(cf[i].flatten())\n",
        "  \n",
        "    model_metrics[\"y_pred\"] = str(y_pred)\n",
        "    model_metrics[\"y_labels\"] = str(test_df_labels)\n",
        "\n",
        "\n",
        "    if threshold != 0.5:\n",
        "      th = \"calculated_threshold\"\n",
        "    else:\n",
        "      th = threshold\n",
        "\n",
        "    model_metrics[\"threshold\"] = th\n",
        "    output_file = \"eval_results_\" + model_name + \"_\"+str(th) +\"_\"+ \".json\"\n",
        "    \n",
        "    with open(output_file, \"w\" ) as writer:\n",
        "        json.dump(model_metrics,writer)\n",
        "  \n",
        "  return model_metrics\n",
        "  # print(\"\\n ROC-AUC score: %.6f \\n\" % (ROC_AUC_score))\n",
        "  # print(\"\\n Subset accuracy : %.6f \\n\" % (accuracy))\n",
        "  # print(\"\\n hamming_loss : %.6f \\n\" % (hloss))\n",
        "\n",
        "  # print(\"  Saving the metrics into a file: \" + output_file + \" with threshold :\" + str(threshold))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpdl9c1mam9K"
      },
      "source": [
        "# Baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGf8u3PSaxxT"
      },
      "source": [
        "## Machine Learning with features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A6p5QlWHuVM"
      },
      "source": [
        "#### SVM Classifier using selected features \n",
        "  * Reference : \n",
        "    1. Linguistic models for detecting bias https://aclanthology.org/P13-1162.pdf\n",
        "    2. Automatically Neutralizing Subjective Bias in Text https://ojs.aaai.org/index.php/AAAI/article/view/5385 \n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG-lILU6b9Wi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkiPd8Zpb9w5"
      },
      "source": [
        "#### Naive Bayes + SVM with log_counts\n",
        "\n",
        "Reference **TBD**:\n",
        "\n",
        "  1. https://nbviewer.jupyter.org/github/amaiya/ktrain/blob/master/tutorials/tutorial-04-text-classification.ipynb\n",
        "  2. https://github.com/mvdheram/Social-bias-Detection/blob/main/Baselines_anti.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjntylgKcs1L",
        "outputId": "25027e78-ef7a-4bea-d1a0-5700ae43fd0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text.print_text_classifiers()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fasttext: a fastText-like model [http://arxiv.org/pdf/1607.01759.pdf]\n",
            "logreg: logistic regression using a trainable Embedding layer\n",
            "nbsvm: NBSVM model [http://www.aclweb.org/anthology/P12-2018]\n",
            "bigru: Bidirectional GRU with pretrained fasttext word vectors [https://fasttext.cc/docs/en/crawl-vectors.html]\n",
            "standard_gru: simple 2-layer GRU with randomly initialized embeddings\n",
            "bert: Bidirectional Encoder Representations from Transformers (BERT) from keras_bert [https://arxiv.org/abs/1810.04805]\n",
            "distilbert: distilled, smaller, and faster BERT from Hugging Face transformers [https://arxiv.org/abs/1910.01108]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Ld-YL7keU2"
      },
      "source": [
        "model = text.text_classifier('nbsvm',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwTACdCka42B"
      },
      "source": [
        "## Pre-trained word embedding models with CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojzQY_d8bRIw"
      },
      "source": [
        "### Word embedding models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzVr-Z3nbUsZ"
      },
      "source": [
        "#### Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx6NltI1abVU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVNgSdinba5S"
      },
      "source": [
        "#### Glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioFZRiI9bcI5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niKpbV5_bcyZ"
      },
      "source": [
        "#### ELMo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jBkfBkTbfwJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5MRFHVebgUi"
      },
      "source": [
        "#### Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utOohuodbhTp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOAm96tebpZh"
      },
      "source": [
        "### Randomly initialized word embeddings with GRU and LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsV6rXkYbySC"
      },
      "source": [
        "#### GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT6QvIzpbvCI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r41NC0jb20Z"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05E4LgwRb35h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}